{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to prepare MERIT data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Date : fev 2024    \n",
    "- Author : G. Sainton    \n",
    "\n",
    "\n",
    "In this Notebook, don't use the LEO data, data must be retrieve from /Data/thnguyen/data/process_FI/ in CALER Server where the original Yamakazi data were stored by Hang.\n",
    "\n",
    "Message from Hang:\n",
    "- /Data/thnguyen/data/LEO/DOWN_xxx_DATA is GIEMS-D3 data (Aires et al., 2017) and not related to MERIT. At that time, GIEMS was downscaled monthly to 90m using HydroSHED data.\n",
    "  xxx is the i-month since January 1993. So, for example, 013 is January 1994.\n",
    "  xxx ranges from 001 to 180 for 180 months in the period 1993-2007.\n",
    "\n",
    "- There are several folders of Yamazaki and they are quite messy. But the \"good\" directory for each variable (slope, HAND, etc.) was appointed by Yamazaki when he copied the folder to us, and I put them in the ̀HydroCell.m.\n",
    "\n",
    "\n",
    "\n",
    "Dependances :\n",
    "- MERIT_DP.m   : code of preprocessing made by Ranuy Fan during his M1 intership. This code is using \n",
    "\n",
    "  - HydroCell.m   \n",
    "  - WindowCell.m\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibPeatland\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibLandsat8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/01_Observatoire/Teledetection/peatland/libLandsat8.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeetools\u001b[39;00m \u001b[38;5;66;03m# the geetools library\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgdown\u001b[39;00m \u001b[38;5;66;03m# the gdown library to download data from Google Drive\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgdal\u001b[39;00m \u001b[38;5;66;03m# the gdal library to read raster data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaskL8sr\u001b[39m(image):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Function to mask clouds using the pixel_qa band of Landsat 8 SR data.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        The cloudmasked Landsat 8 image\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gdal'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "\n",
    "# allow images to display in the notebook\n",
    "from IPython.display import Image\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import libraries\n",
    "import json\n",
    "from libPeatland import *\n",
    "from libLandsat8 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AOI\n",
    "\n",
    "Just beware that the AOI here is the same that in the other Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "AOI = {\"xmin\": -103.1, \"ymin\": 47.9, \"xmax\": -79.2, \"ymax\": 60.5} # Hudson Bay\n",
    "#AOI ={\"xmin\": 58.5, \"ymin\": 54.8, \"xmax\": 90.1, \"ymax\": 70.7} # Russia\n",
    "#AOI = {\"xmin\": 24, \"ymin\": 62.9, \"xmax\": 29.06, \"ymax\": 68.1} # Finland\n",
    "\n",
    "# Parameters\n",
    "plot_maps = True\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path2merit -> \n",
    "# beware to mount the volume MERIT on CALER first\n",
    "path2merit = \"/home/gsainton/MERIT/Yamazaki/MERIT/v0.4_original_data_distributed\"\n",
    "\n",
    "# Directory with the width data\n",
    "width_data_dir = os.path.join(path2merit, \"width\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(width_data_dir):\n",
    "    print(\"Directory exists: \", width_data_dir)\n",
    "else:\n",
    "    sys.exit(f\"Check if the directory exists: {width_data_dir} of is properly mounted\")\n",
    "# get the list of file in the directory\n",
    "list_files = os.listdir(width_data_dir)\n",
    "\n",
    "# Number of files in the directory\n",
    "print(\"Number of files in the directory: \", len(list_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dataframe with the list of files\n",
    "df_merit = pd.DataFrame(columns=[\"file_name\"])\n",
    "\n",
    "df_merit[\"file_name\"] = list_files \n",
    "df_merit[\"file_path\"] = df_merit[\"file_name\"]\n",
    "df_merit[\"file_type\"] = df_merit[\"file_name\"].apply(lambda x: x.split(\".\")[-2])\n",
    "\n",
    "# Split the file name to extract the latitude\n",
    "df_merit[\"file_name\"] = df_merit[\"file_name\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "# if the fist character is a \"s\", the latitude is negative\n",
    "df_merit[\"lat_start\"] = df_merit[\"file_name\"].apply(lambda x: -int(x[1:3]) if x[0] == \"s\" else int(x[1:3]))\n",
    "# if the 4th character is a \"w\", the longitude is negative\n",
    "df_merit[\"lon_start\"] = df_merit[\"file_name\"].apply(lambda x: -int(x[4:7]) if x[3] == \"w\" else int(x[4:7]))\n",
    "\n",
    "\n",
    "display(df_merit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the AOI\n",
    "df_merit = df_merit[(df_merit[\"lat_start\"] >= AOI[\"ymin\"]) & (df_merit[\"lat_start\"]+5 <= AOI[\"ymax\"])]\n",
    "df_merit = df_merit[(df_merit[\"lon_start\"] >= AOI[\"xmin\"]) & (df_merit[\"lon_start\"]+5 <= AOI[\"xmax\"])]\n",
    "\n",
    "# Order by latitude and longitude\n",
    "df_merit = df_merit.sort_values(by=[\"lat_start\", \"lon_start\"])\n",
    "\n",
    "print(\"Number of files in the AOI: \", df_merit.shape[0])\n",
    "\n",
    "print(AOI)\n",
    "display(df_merit.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
